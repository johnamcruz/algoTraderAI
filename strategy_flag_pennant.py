#!/usr/bin/env python3
"""
Flag/Pennant Transformer V2.4 Strategy - PRODUCTION-READY
================================================================================
âœ… 15min pattern detection + 3min entry timing
âœ… 27 features (19 base pattern + 8 volume indicators)
âœ… 65% confidence threshold (2-5 trades/day)
âœ… 2:1 R:R ratio (8pts stop, 16pts target)
âœ… Expected: 60-70% win rate, 2-5 trades/day

DATA REQUIREMENTS:
- Minimum: 150 bars (~7.5 hours / 1 trading day)
  - Needed for 50-period EMA + 20-period indicators
- Recommended: 200+ bars (~10 hours / 1.5 days) for stable features
- Optimal: 300+ bars (~15 hours / 2 days) for excellent quality

EXECUTION: Runs every 3 minutes on 3-minute bars
================================================================================
"""

import pandas as pd
import numpy as np
import onnxruntime
import pickle
import os
import logging
from typing import Dict, List, Tuple, Optional
from strategy_base import BaseStrategy

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


class FlagPennantStrategy(BaseStrategy):
    """Flag/Pennant Transformer V2.4 - PRODUCTION-READY"""

    def __init__(self, model_path: str, scaler_path: str, contract_symbol: str):
        """Initialize Flag/Pennant V2.4 Strategy"""
        super().__init__(model_path, scaler_path, contract_symbol)
        
        self.bar_count = 0
        self.last_quality = None
        
        # CRITICAL: Label remapping (model outputs are swapped)
        self.remap_labels = True

    def get_feature_columns(self) -> List[str]:
        """Returns the 27 Flag/Pennant feature columns"""
        return [
            # Price action patterns (8)
            'price_range_compression', 'price_volatility_ratio', 'consolidation_score',
            'breakout_readiness', 'pattern_tightness', 'trend_continuation_score',
            'pole_strength', 'flag_symmetry',
            
            # Trendline indicators (6)
            'upper_trendline_slope', 'lower_trendline_slope', 'trendline_convergence',
            'price_to_upper_trend', 'price_to_lower_trend', 'channel_width',
            
            # Momentum indicators (5)
            'rsi_14', 'rsi_slope', 'macd_signal', 'momentum_divergence', 'acceleration',
            
            # Volume indicators (8)
            'volume_trend', 'volume_breakout_score', 'volume_contraction',
            'volume_surge_detection', 'obv_trend', 'volume_price_divergence',
            'volume_oscillator', 'volume_confirmation',
        ]

    def get_sequence_length(self) -> int:
        """Flag/Pennant V2.4 uses 80 bars"""
        return 80
    
    def get_quality_level(self, bars: int) -> str:
        """Return data quality level based on bar count"""
        if bars < 150:
            return "INSUFFICIENT"
        elif bars < 200:
            return "WARMING_UP"
        elif bars < 300:
            return "GOOD"
        else:
            return "EXCELLENT"
    
    def _remap_prediction(self, pred: int) -> int:
        """
        Remap prediction to fix BUY/SELL swap
        Model output: 0=HOLD, 1=SELL, 2=BUY (based on observed distribution)
        Strategy needs: 0=HOLD, 1=BUY, 2=SELL
        """
        if not self.remap_labels:
            return pred
        
        if pred == 1:  # Model says 1 â†’ make it 2 (SELL)
            return 2
        elif pred == 2:  # Model says 2 â†’ make it 1 (BUY)
            return 1
        else:
            return pred  # HOLD stays HOLD

    def add_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Calculate Flag/Pennant V2.4 features (27 total)
        
        WARMUP PERIODS:
        - RSI: 14 bars
        - EMA: 50 bars (longest)
        - Swing highs/lows: 5 bars (center=True adds 2.5 on each side)
        - Total minimum: ~100 bars for basic features
        - Recommended: 200+ bars for stable features
        """
        self.bar_count += 1
        current_bars = len(df)
        quality = self.get_quality_level(current_bars)
        
        # Log quality changes
        if quality != self.last_quality:
            if quality == "INSUFFICIENT":
                logging.warning(f"âš ï¸ INSUFFICIENT DATA: {current_bars} bars (need 150+)")
            elif quality == "WARMING_UP":
                logging.info(f"ðŸ”¥ WARMING UP: {current_bars} bars - predictions starting")
            elif quality == "GOOD":
                logging.info(f"âœ… GOOD QUALITY: {current_bars} bars - features stable")
            elif quality == "EXCELLENT":
                logging.info(f"ðŸŽ¯ EXCELLENT: {current_bars} bars - full quality achieved")
            self.last_quality = quality
        
        df = df.copy()
        
        # Import pandas_ta for consistent calculation
        try:
            import pandas_ta as ta
        except ImportError:
            raise ImportError("pandas_ta required. Install with: pip install pandas_ta")
        
        # =====================================================================
        # PRICE ACTION PATTERNS (8 features)
        # =====================================================================
        
        # 1. Price range compression
        high_low_range = df['high'] - df['low']
        range_ma = high_low_range.rolling(20, min_periods=10).mean()
        df['price_range_compression'] = (high_low_range / (range_ma + 1e-6)).fillna(1.0)
        
        # 2. Price volatility ratio
        returns = df['close'].pct_change()
        volatility_short = returns.rolling(10, min_periods=5).std()
        volatility_long = returns.rolling(50, min_periods=20).std()
        df['price_volatility_ratio'] = (volatility_short / (volatility_long + 1e-6)).fillna(1.0)
        
        # 3. Consolidation score (how tight price is trading)
        bb_width = df['high'].rolling(20, min_periods=10).max() - df['low'].rolling(20, min_periods=10).min()
        bb_mean = df['close'].rolling(20, min_periods=10).mean()
        df['consolidation_score'] = 1.0 - (bb_width / (bb_mean + 1e-6)).clip(0, 2)
        
        # 4. Breakout readiness (price near edge of range)
        recent_high = df['high'].rolling(20, min_periods=10).max()
        recent_low = df['low'].rolling(20, min_periods=10).min()
        price_position = (df['close'] - recent_low) / (recent_high - recent_low + 1e-6)
        df['breakout_readiness'] = np.abs(price_position - 0.5) * 2  # 0 at middle, 1 at edges
        
        # 5. Pattern tightness (how compressed the pattern is)
        atr_short = (df['high'] - df['low']).rolling(5, min_periods=3).mean()
        atr_long = (df['high'] - df['low']).rolling(20, min_periods=10).mean()
        df['pattern_tightness'] = (atr_short / (atr_long + 1e-6)).fillna(1.0)
        
        # 6. Trend continuation score (is there a clear trend before?)
        ema_fast = df['close'].ewm(span=20, min_periods=10).mean()
        ema_slow = df['close'].ewm(span=50, min_periods=20).mean()
        df['trend_continuation_score'] = ((ema_fast - ema_slow) / (ema_slow + 1e-6)).fillna(0)
        
        # 7. Pole strength (strength of move before consolidation)
        price_change_20 = df['close'].pct_change(20)
        price_change_50 = df['close'].pct_change(50)
        df['pole_strength'] = (price_change_20 / (price_change_50.abs() + 1e-6)).fillna(0)
        
        # 8. Flag symmetry (is consolidation balanced?)
        upper_touches = (df['high'] >= df['high'].rolling(10, min_periods=5).max()).rolling(20, min_periods=10).sum()
        lower_touches = (df['low'] <= df['low'].rolling(10, min_periods=5).min()).rolling(20, min_periods=10).sum()
        df['flag_symmetry'] = 1.0 - np.abs(upper_touches - lower_touches) / 20.0
        
        # =====================================================================
        # TRENDLINE INDICATORS (6 features)
        # =====================================================================
        
        # Calculate swing highs and lows for trendlines
        swing_high = df['high'].rolling(5, center=True, min_periods=3).max()
        swing_low = df['low'].rolling(5, center=True, min_periods=3).min()
        
        # 9-10. Trendline slopes
        df['upper_trendline_slope'] = swing_high.diff(10) / 10
        df['lower_trendline_slope'] = swing_low.diff(10) / 10
        
        # 11. Trendline convergence (are lines getting closer?)
        trendline_distance = swing_high - swing_low
        distance_slope = trendline_distance.diff(10)
        df['trendline_convergence'] = -distance_slope / (trendline_distance + 1e-6)
        
        # 12-13. Price position relative to trendlines
        df['price_to_upper_trend'] = (swing_high - df['close']) / (swing_high + 1e-6)
        df['price_to_lower_trend'] = (df['close'] - swing_low) / (df['close'] + 1e-6)
        
        # 14. Channel width
        df['channel_width'] = (swing_high - swing_low) / (df['close'] + 1e-6)
        
        # =====================================================================
        # MOMENTUM INDICATORS (5 features)
        # =====================================================================
        
        # 15. RSI
        delta = df['close'].diff()
        gain = delta.where(delta > 0, 0).rolling(14, min_periods=7).mean()
        loss = -delta.where(delta < 0, 0).rolling(14, min_periods=7).mean()
        rs = gain / (loss + 1e-6)
        df['rsi_14'] = 100 - (100 / (1 + rs))
        df['rsi_14'] = df['rsi_14'].fillna(50)
        
        # 16. RSI slope
        df['rsi_slope'] = df['rsi_14'].diff(3)
        
        # 17. MACD signal
        ema12 = df['close'].ewm(span=12, min_periods=6).mean()
        ema26 = df['close'].ewm(span=26, min_periods=13).mean()
        macd = ema12 - ema26
        signal = macd.ewm(span=9, min_periods=5).mean()
        df['macd_signal'] = macd - signal
        
        # 18. Momentum divergence (price vs momentum)
        momentum = df['close'].diff(10)
        momentum_ma = momentum.rolling(20, min_periods=10).mean()
        df['momentum_divergence'] = (momentum - momentum_ma) / (momentum_ma.abs() + 1e-6)
        
        # 19. Acceleration (rate of change of momentum)
        df['acceleration'] = momentum.diff(5) / 5
        
        # =====================================================================
        # VOLUME INDICATORS (8 features)
        # =====================================================================
        
        if 'volume' not in df.columns or df['volume'].sum() == 0:
            # No volume data - use zero features
            for col in ['volume_trend', 'volume_breakout_score', 'volume_contraction',
                       'volume_surge_detection', 'obv_trend', 'volume_price_divergence',
                       'volume_oscillator', 'volume_confirmation']:
                df[col] = 0.0
        else:
            # 20. Volume trend
            volume_ma_short = df['volume'].rolling(10, min_periods=5).mean()
            volume_ma_long = df['volume'].rolling(50, min_periods=20).mean()
            df['volume_trend'] = (volume_ma_short / (volume_ma_long + 1e-6)).fillna(1.0)
            
            # 21. Volume breakout score
            volume_std = df['volume'].rolling(20, min_periods=10).std()
            volume_zscore = (df['volume'] - volume_ma_short) / (volume_std + 1e-6)
            df['volume_breakout_score'] = volume_zscore.clip(-3, 3) / 3.0
            
            # 22. Volume contraction (decreasing volume during consolidation)
            volume_slope = df['volume'].rolling(10, min_periods=5).apply(
                lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) >= 5 else 0, raw=True
            )
            df['volume_contraction'] = -volume_slope / (df['volume'].mean() + 1e-6)
            
            # 23. Volume surge detection
            volume_surge = df['volume'] > (volume_ma_short + 2 * volume_std)
            df['volume_surge_detection'] = volume_surge.astype(float)
            
            # 24. OBV trend
            obv = (np.sign(df['close'].diff()) * df['volume']).fillna(0).cumsum()
            obv_ma = obv.rolling(20, min_periods=10).mean()
            df['obv_trend'] = (obv - obv_ma) / (obv_ma.abs() + 1e-6)
            
            # 25. Volume-price divergence
            price_trend = df['close'].rolling(20, min_periods=10).apply(
                lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) >= 10 else 0, raw=True
            )
            volume_trend_slope = df['volume'].rolling(20, min_periods=10).apply(
                lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) >= 10 else 0, raw=True
            )
            df['volume_price_divergence'] = (np.sign(price_trend) != np.sign(volume_trend_slope)).astype(float)
            
            # 26. Volume oscillator
            volume_short = df['volume'].rolling(5, min_periods=3).mean()
            volume_long = df['volume'].rolling(20, min_periods=10).mean()
            df['volume_oscillator'] = (volume_short - volume_long) / (volume_long + 1e-6)
            
            # 27. Volume confirmation (volume supporting price move)
            price_change = df['close'].pct_change(5)
            volume_change = df['volume'].pct_change(5)
            df['volume_confirmation'] = (np.sign(price_change) == np.sign(volume_change)).astype(float)
        
        # =====================================================================
        # CLEANUP
        # =====================================================================
        
        df.replace([np.inf, -np.inf], np.nan, inplace=True)
        df.fillna(method='ffill', inplace=True)
        df.fillna(0, inplace=True)
        
        # Clip extreme values
        feature_cols = self.get_feature_columns()
        for col in feature_cols:
            if col in df.columns:
                df[col] = df[col].clip(-10, 10)
        
        return df

    def load_model(self):
        """Load ONNX model"""
        try:
            if not os.path.exists(self.model_path):
                raise FileNotFoundError(f"Model file not found: {self.model_path}")
            self.model = onnxruntime.InferenceSession(self.model_path)
            logging.info(f"âœ… Loaded Flag/Pennant V2.4 model: {os.path.basename(self.model_path)}")
        except Exception as e:
            logging.exception(f"âŒ Error loading model: {e}")
            raise

    def load_scaler(self):
        """Load scaler"""
        try:
            if not os.path.exists(self.scaler_path):
                raise FileNotFoundError(f"Scaler file not found: {self.scaler_path}")
            with open(self.scaler_path, 'rb') as f:
                scalers = pickle.load(f)
            
            # Extract base symbol (ES or NQ)
            base_symbol = self.contract_symbol.split('.')[0][:2]
            
            if base_symbol in scalers:
                self.scaler = scalers[base_symbol]
                logging.info(f"âœ… Loaded '{base_symbol}' scaler for Flag/Pennant V2.4")
            else:
                available = list(scalers.keys())
                raise ValueError(f"'{base_symbol}' scaler not found. Available: {available}")
        except Exception as e:
            logging.exception(f"âŒ Error loading scaler: {e}")
            raise

    def predict(self, df: pd.DataFrame) -> Tuple[int, float]:
        """
        Generate prediction from Flag/Pennant V2.4 model
        
        Returns:
            prediction: 0=HOLD, 1=BUY, 2=SELL (after remapping)
            confidence: Model confidence (0-1)
        """
        try:
            seq_len = self.get_sequence_length()
            current_bars = len(df)
            
            # Need minimum bars for features + sequence
            if df.empty or current_bars < 150:
                if self.bar_count % 50 == 0:  # Log every 50 bars
                    logging.info(f"â³ Accumulating data: {current_bars}/150 bars")
                return 0, 0.0

            features = self.preprocess_features(df)
            if len(features) < seq_len:
                return 0, 0.0

            X = features[-seq_len:].reshape(1, seq_len, -1).astype(np.float32)
            
            if np.isnan(X).any() or np.isinf(X).any():
                logging.error(f"âŒ Invalid values detected in input")
                return 0, 0.0

            # Run inference
            outputs = self.model.run(None, {'input_sequence': X})
            
            # Get logits and confidence
            logits_sequence = outputs[0]
            last_logits = logits_sequence[0, -1, :]
            
            # Get confidence from auxiliary head
            confidence_sequence = outputs[2]
            confidence_pred = float(confidence_sequence[0, -1])
            
            probs = self._softmax(last_logits)
            prediction = int(np.argmax(probs))
            
            # CRITICAL: Remap prediction (BUY â†” SELL swap)
            prediction = self._remap_prediction(prediction)
            
            # Use auxiliary confidence
            confidence = confidence_pred
            
            pred_name = ['HOLD', 'BUY', 'SELL'][prediction]
            quality = self.get_quality_level(current_bars)
            
            # Log signals and periodic status
            if prediction != 0:
                logging.info(f"ðŸŽ¯ [{quality}] {pred_name} (Conf: {confidence:.3f}) | Bars: {current_bars}")
            elif self.bar_count % 100 == 0:
                logging.debug(f"ðŸ“Š [{quality}] {pred_name} (Conf: {confidence:.3f}) | Bars: {current_bars}")

            return prediction, confidence

        except Exception as e:
            logging.exception(f"âŒ Prediction error: {e}")
            return 0, 0.0

    def should_enter_trade(
        self,
        prediction: int,
        confidence: float,
        bar: Dict,
        entry_conf: float = 0.65,
        adx_thresh: float = 0.0,
    ) -> Tuple[bool, Optional[str]]:
        """
        Determine if entry conditions are met for Flag/Pennant V2.4
                
        Args:
            prediction: Model prediction (0=HOLD, 1=BUY, 2=SELL)
            confidence: Model confidence (0-1)
            bar: Current bar data (not used, kept for compatibility)
            entry_conf: Confidence threshold (default 0.65)
            adx_thresh: Not used (kept for compatibility)
        
        Returns:
            (should_enter, direction): (True, 'LONG') or (False, None)
        """
        if confidence < entry_conf:
            return False, None
        
        quality = self.get_quality_level(self.bar_count)
        
        # Only trade BUY signals (prediction == 1 after remapping)
        if prediction == 1:
            return True, 'LONG'
        
        elif prediction == 2:
            return False, None
        
        return False, None

    @staticmethod
    def _softmax(x):
        """Compute softmax values for array x"""
        if x is None or len(x) == 0:
            return np.array([])
        exp_x = np.exp(x - np.max(x))
        return exp_x / exp_x.sum()